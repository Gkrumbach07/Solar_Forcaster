{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Data\n",
    "This notebook combines the hourly data into daily data. The benifift of this is that the hourly data contains timing errors when merging the dataset. Keeping the data hourly would increase the number of samples, but also increase the number of bad samples.\n",
    "\n",
    "We will also calculate the solar efficiency rather than having a actual output. This makes the data more readable and trainable for our model.\n",
    "\n",
    "First we read in our data we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the clearsky values (maximum output) and the actual collected output into efficiency percentages. This will make comparing days easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make percent attained row\n",
    "df[\"dhi_efficiency\"] = df[\"DHI\"]/df[\"Clearsky DHI\"]\n",
    "df[\"dni_efficiency\"] = df[\"DNI\"]/df[\"Clearsky DNI\"]\n",
    "df[\"ghi_efficiency\"] = df[\"GHI\"]/df[\"Clearsky GHI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate hours into days\n",
    "Next we are setting the index of our dataset to the `DATE` column. This will make it easier to group together rows by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "df['DATE'] =  pd.to_datetime(df['DATE'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.set_index('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are removing all hours of the day where there was no sunlight. To do this we use a little trick in our dataset. The efficiency values we created are based off the clearsky models which are directly correlated with sunlight. Thus when we preformed the division, non-sunlight hours had an efficiacy of NaN. We can exploit this by removing all columns that returned null, or the night hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df[df['dhi_efficiency'].notnull()]  \n",
    "grouped = grouped.groupby('STATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we aggregate the data into days. For most columns we take the average, except for meta data values such as long, lat, and elevation. We will deal with the categorical data (cloud and weather type) next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interval to aggregate on\n",
    "agg_intv = 'D'\n",
    "\n",
    "daily_summary = pd.DataFrame()\n",
    "\n",
    "daily_summary['latitude'] = grouped['latitude'].resample(agg_intv).last()\n",
    "daily_summary['longitude'] = grouped['longitude'].resample(agg_intv).last()\n",
    "daily_summary['elevation'] = grouped['elevation'].resample(agg_intv).last()\n",
    "\n",
    "daily_summary['temperature'] = grouped.Temperature.resample(agg_intv).mean()\n",
    "daily_summary['dew_point'] = grouped['Dew Point'].resample(agg_intv).mean()\n",
    "daily_summary['relative_humidity'] = grouped['Relative Humidity'].resample(agg_intv).mean()\n",
    "daily_summary['daily_precipitation'] = grouped['HourlyPrecipitation'].resample(agg_intv).mean()\n",
    "daily_summary['station_pressure'] = grouped.HourlyStationPressure.resample(agg_intv).mean()\n",
    "daily_summary['relative_humidity'] = grouped['Relative Humidity'].resample(agg_intv).mean()\n",
    "daily_summary['wind_direction'] = grouped['Wind Direction'].resample(agg_intv).mean()\n",
    "daily_summary['wind_speed'] = grouped['Wind Speed'].resample(agg_intv).mean()\n",
    "daily_summary['hourly_visibility'] = grouped['HourlyVisibility'].resample(agg_intv).mean()\n",
    "daily_summary['cloud_cover'] = grouped['cloud_cover'].resample(agg_intv).mean()\n",
    "\n",
    "daily_summary['cloud_type'] = grouped['cloud_type'].resample(agg_intv).apply(pd.array)\n",
    "daily_summary['weather_type'] = grouped['weather_type'].resample(agg_intv).apply(pd.array)\n",
    "\n",
    "daily_summary['dhi_efficiency'] = grouped['dhi_efficiency'].resample(agg_intv).mean()\n",
    "daily_summary['dni_efficiency'] = grouped['dni_efficiency'].resample(agg_intv).mean()\n",
    "daily_summary['ghi_efficiency'] = grouped['ghi_efficiency'].resample(agg_intv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten categorical data\n",
    "First we import the lookup json files that we used in the first notebook. We use these to grab an array of every possible value each cell could be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "cloud_types = []\n",
    "with open('cloud_lookup.json') as json_file:\n",
    "    cloud_json = json.load(json_file).values()\n",
    "    for x in cloud_json:\n",
    "        cloud_types.append(x['cloud_str'])\n",
    "    cloud_types = list(dict.fromkeys(cloud_types))\n",
    "    \n",
    "with open('weather_lookup_converter.json') as json_file:\n",
    "    weather_types = list(json.load(json_file).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add each of the possible cloud and weather types to the dataset as its own column. Then we add the count for each type into its respective column. Then we join this flattened data with the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>station_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>hourly_visibility</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>cloud_type</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>dhi_efficiency</th>\n",
       "      <th>dni_efficiency</th>\n",
       "      <th>ghi_efficiency</th>\n",
       "      <th>mostly_cloudy</th>\n",
       "      <th>mostly_clear</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>overcast</th>\n",
       "      <th>rain_light</th>\n",
       "      <th>tstorm</th>\n",
       "      <th>drizzle</th>\n",
       "      <th>rain_heavy</th>\n",
       "      <th>rain</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow_light</th>\n",
       "      <th>snow</th>\n",
       "      <th>snow_heavy</th>\n",
       "      <th>freezing_rain</th>\n",
       "      <th>freezing_drizzle</th>\n",
       "      <th>ice_pellets</th>\n",
       "      <th>ice_pellets_light</th>\n",
       "      <th>ice_pellets_heavy</th>\n",
       "      <th>flurries</th>\n",
       "      <th>freezing_rain_heavy</th>\n",
       "      <th>freezing_rain_light</th>\n",
       "      <th>fog_light</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">121</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>32.15</td>\n",
       "      <td>-111.167</td>\n",
       "      <td>737.0</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>75.717778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.327778</td>\n",
       "      <td>243.444444</td>\n",
       "      <td>4.755556</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>[mostly_cloudy, mostly_clear, mostly_cloudy, m...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>1.447492</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>32.15</td>\n",
       "      <td>-111.167</td>\n",
       "      <td>737.0</td>\n",
       "      <td>11.888889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>50.391111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.564444</td>\n",
       "      <td>206.288889</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[clear, clear, clear, clear, clear, clear, cle...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>2.387190</td>\n",
       "      <td>0.453998</td>\n",
       "      <td>0.733653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>32.15</td>\n",
       "      <td>-111.167</td>\n",
       "      <td>737.0</td>\n",
       "      <td>16.111111</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>36.868889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.617778</td>\n",
       "      <td>205.566667</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[clear, clear, clear, clear, clear, clear, cle...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>1.693041</td>\n",
       "      <td>0.572070</td>\n",
       "      <td>0.771071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>32.15</td>\n",
       "      <td>-111.167</td>\n",
       "      <td>737.0</td>\n",
       "      <td>17.888889</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.560000</td>\n",
       "      <td>243.244444</td>\n",
       "      <td>1.911111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[clear, clear, clear, clear, clear, clear, cle...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>1.157926</td>\n",
       "      <td>0.949705</td>\n",
       "      <td>0.975965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>32.15</td>\n",
       "      <td>-111.167</td>\n",
       "      <td>737.0</td>\n",
       "      <td>17.444444</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>46.236667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.436667</td>\n",
       "      <td>257.822222</td>\n",
       "      <td>4.155556</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[clear, clear, clear, clear, clear, clear, cle...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>1.003678</td>\n",
       "      <td>0.989174</td>\n",
       "      <td>0.991972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    latitude  longitude  elevation  temperature  dew_point  \\\n",
       "STATION DATE                                                                 \n",
       "121     2017-01-01     32.15   -111.167      737.0     9.555556   3.555556   \n",
       "        2017-01-02     32.15   -111.167      737.0    11.888889   0.444444   \n",
       "        2017-01-03     32.15   -111.167      737.0    16.111111  -0.444444   \n",
       "        2017-01-04     32.15   -111.167      737.0    17.888889   1.111111   \n",
       "        2017-01-05     32.15   -111.167      737.0    17.444444   4.111111   \n",
       "\n",
       "                    relative_humidity  daily_precipitation  station_pressure  \\\n",
       "STATION DATE                                                                   \n",
       "121     2017-01-01          75.717778                  NaN         27.327778   \n",
       "        2017-01-02          50.391111                  NaN         27.564444   \n",
       "        2017-01-03          36.868889                  NaN         27.617778   \n",
       "        2017-01-04          36.750000                  NaN         27.560000   \n",
       "        2017-01-05          46.236667                  NaN         27.436667   \n",
       "\n",
       "                    wind_direction  wind_speed  hourly_visibility  \\\n",
       "STATION DATE                                                        \n",
       "121     2017-01-01      243.444444    4.755556               10.0   \n",
       "        2017-01-02      206.288889    2.622222               10.0   \n",
       "        2017-01-03      205.566667    1.566667               10.0   \n",
       "        2017-01-04      243.244444    1.911111               10.0   \n",
       "        2017-01-05      257.822222    4.155556               10.0   \n",
       "\n",
       "                    cloud_cover  \\\n",
       "STATION DATE                      \n",
       "121     2017-01-01     0.488889   \n",
       "        2017-01-02     0.000000   \n",
       "        2017-01-03     0.000000   \n",
       "        2017-01-04     0.000000   \n",
       "        2017-01-05     0.000000   \n",
       "\n",
       "                                                           cloud_type  \\\n",
       "STATION DATE                                                            \n",
       "121     2017-01-01  [mostly_cloudy, mostly_clear, mostly_cloudy, m...   \n",
       "        2017-01-02  [clear, clear, clear, clear, clear, clear, cle...   \n",
       "        2017-01-03  [clear, clear, clear, clear, clear, clear, cle...   \n",
       "        2017-01-04  [clear, clear, clear, clear, clear, clear, cle...   \n",
       "        2017-01-05  [clear, clear, clear, clear, clear, clear, cle...   \n",
       "\n",
       "                                                     weather_type  \\\n",
       "STATION DATE                                                        \n",
       "121     2017-01-01  [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "        2017-01-02  [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "        2017-01-03  [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "        2017-01-04  [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "        2017-01-05  [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                    dhi_efficiency  dni_efficiency  ghi_efficiency  \\\n",
       "STATION DATE                                                         \n",
       "121     2017-01-01        1.447492        0.450007        0.625793   \n",
       "        2017-01-02        2.387190        0.453998        0.733653   \n",
       "        2017-01-03        1.693041        0.572070        0.771071   \n",
       "        2017-01-04        1.157926        0.949705        0.975965   \n",
       "        2017-01-05        1.003678        0.989174        0.991972   \n",
       "\n",
       "                    mostly_cloudy  mostly_clear  clear  cloudy  partly_cloudy  \\\n",
       "STATION DATE                                                                    \n",
       "121     2017-01-01            4.0           2.0    1.0     2.0            0.0   \n",
       "        2017-01-02            0.0           0.0    9.0     0.0            0.0   \n",
       "        2017-01-03            0.0           0.0    9.0     0.0            0.0   \n",
       "        2017-01-04            0.0           0.0    9.0     0.0            0.0   \n",
       "        2017-01-05            0.0           0.0    9.0     0.0            0.0   \n",
       "\n",
       "                    overcast  rain_light  tstorm  drizzle  rain_heavy  rain  \\\n",
       "STATION DATE                                                                  \n",
       "121     2017-01-01       0.0         0.0     0.0      0.0         0.0   0.0   \n",
       "        2017-01-02       0.0         0.0     0.0      0.0         0.0   0.0   \n",
       "        2017-01-03       0.0         0.0     0.0      0.0         0.0   0.0   \n",
       "        2017-01-04       0.0         0.0     0.0      0.0         0.0   0.0   \n",
       "        2017-01-05       0.0         0.0     0.0      0.0         0.0   0.0   \n",
       "\n",
       "                    fog  snow_light  snow  snow_heavy  freezing_rain  \\\n",
       "STATION DATE                                                           \n",
       "121     2017-01-01  0.0         0.0   0.0         0.0            0.0   \n",
       "        2017-01-02  0.0         0.0   0.0         0.0            0.0   \n",
       "        2017-01-03  0.0         0.0   0.0         0.0            0.0   \n",
       "        2017-01-04  0.0         0.0   0.0         0.0            0.0   \n",
       "        2017-01-05  0.0         0.0   0.0         0.0            0.0   \n",
       "\n",
       "                    freezing_drizzle  ice_pellets  ice_pellets_light  \\\n",
       "STATION DATE                                                           \n",
       "121     2017-01-01               0.0          0.0                0.0   \n",
       "        2017-01-02               0.0          0.0                0.0   \n",
       "        2017-01-03               0.0          0.0                0.0   \n",
       "        2017-01-04               0.0          0.0                0.0   \n",
       "        2017-01-05               0.0          0.0                0.0   \n",
       "\n",
       "                    ice_pellets_heavy  flurries  freezing_rain_heavy  \\\n",
       "STATION DATE                                                           \n",
       "121     2017-01-01                0.0       0.0                  0.0   \n",
       "        2017-01-02                0.0       0.0                  0.0   \n",
       "        2017-01-03                0.0       0.0                  0.0   \n",
       "        2017-01-04                0.0       0.0                  0.0   \n",
       "        2017-01-05                0.0       0.0                  0.0   \n",
       "\n",
       "                    freezing_rain_light  fog_light  \n",
       "STATION DATE                                        \n",
       "121     2017-01-01                  0.0        0.0  \n",
       "        2017-01-02                  0.0        0.0  \n",
       "        2017-01-03                  0.0        0.0  \n",
       "        2017-01-04                  0.0        0.0  \n",
       "        2017-01-05                  0.0        0.0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate cloud column    \n",
    "cloud_sep = pd.DataFrame([x for x in daily_summary['cloud_type'].apply(\n",
    "    lambda item: dict(map(lambda x: (x, np.count_nonzero(item.to_numpy() == x)), item))).values]).fillna(0)\n",
    "\n",
    "cloud_sep = cloud_sep.append(pd.DataFrame(columns = cloud_types)).fillna(0.0)\n",
    "cloud_sep = cloud_sep.loc[:, cloud_sep.columns.notnull()]\n",
    "cloud_sep = cloud_sep.set_index(daily_summary.index)\n",
    "daily_summary = daily_summary.join(cloud_sep)\n",
    "\n",
    "# seperate weather column    \n",
    "weather_sep = pd.DataFrame([x for x in daily_summary['weather_type'].apply(\n",
    "    lambda item: dict(map(lambda x: (x, np.count_nonzero(item.to_numpy() == x)), item))).values]).fillna(0)\n",
    "\n",
    "weather_sep = weather_sep.append(pd.DataFrame(columns = weather_types)).fillna(0.0)\n",
    "weather_sep = weather_sep.loc[:, weather_sep.columns.notnull()]\n",
    "weather_sep = weather_sep.set_index(daily_summary.index)\n",
    "daily_summary = daily_summary.join(weather_sep)\n",
    "\n",
    "daily_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save aggregated data\n",
    "To finish this notebook and save its changes, we drop unnecessary columns, clean up NaN values, and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary = daily_summary.reset_index(drop=False)\n",
    "daily_summary = daily_summary.drop(columns=['cloud_type', 'weather_type', 'elevation', 'wind_direction'])\n",
    "daily_summary = daily_summary.dropna()\n",
    "daily_summary = daily_summary.reset_index(drop=True)\n",
    "daily_summary.to_parquet('solar_cleaned.parquet', engine='fastparquet', compression='GZIP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
